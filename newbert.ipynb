{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at nlpaueb/legal-bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF-based Legal Chatbot is ready! You can ask questions.\n",
      "Type 'exit' to quit the chat.\n",
      "Bot: elevations\n",
      "Bot: elevations\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForQuestionAnswering\n",
    "import torch\n",
    "\n",
    "# Check if GPU is available, and use it if possible\n",
    "device = 0 if torch.cuda.is_available() else -1  # -1 means CPU, 0 means GPU\n",
    "\n",
    "# Initialize the model and tokenizer from Hugging Face\n",
    "model_name = \"nlpaueb/legal-bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "\n",
    "# Initialize the QA pipeline with the correct device\n",
    "qa_pipeline = pipeline(\"question-answering\", model=model, tokenizer=tokenizer, device=device)\n",
    "\n",
    "# Directory containing PDF files\n",
    "pdf_directory = \"pdf\"\n",
    "\n",
    "# Function to extract text from PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with open(pdf_path, \"rb\") as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            for page_num in range(len(reader.pages)):\n",
    "                page = reader.pages[page_num]\n",
    "                text += page.extract_text()\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {pdf_path}: {e}\")\n",
    "    return text\n",
    "\n",
    "# Function to load all PDFs in a directory\n",
    "def load_pdfs_from_directory(directory):\n",
    "    pdf_texts = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            pdf_path = os.path.join(directory, filename)\n",
    "            pdf_text = extract_text_from_pdf(pdf_path)\n",
    "            if pdf_text.strip():\n",
    "                pdf_texts.append(pdf_text)\n",
    "    return pdf_texts\n",
    "\n",
    "# Function to answer a question using the PDF contents\n",
    "def answer_question(question, pdf_texts):\n",
    "    # Combine all PDF text into one context\n",
    "    context = \" \".join(pdf_texts)\n",
    "    \n",
    "    # Use the QA pipeline to answer the question\n",
    "    result = qa_pipeline(question=question, context=context)\n",
    "    return result['answer']\n",
    "\n",
    "# Main interaction loop\n",
    "def chat_with_pdf_bot():\n",
    "    pdf_texts = load_pdfs_from_directory(pdf_directory)\n",
    "    if not pdf_texts:\n",
    "        print(\"No PDFs found or extracted text is empty.\")\n",
    "        return\n",
    "    \n",
    "    print(\"PDF-based Legal Chatbot is ready! You can ask questions.\")\n",
    "    print(\"Type 'exit' to quit the chat.\")\n",
    "    \n",
    "    while True:\n",
    "        # User asks a question\n",
    "        question = input(\"You: \")\n",
    "        if question.lower() == 'exit':\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        # Answer the question based on PDF content\n",
    "        answer = answer_question(question, pdf_texts)\n",
    "        print(f\"Bot: {answer}\")\n",
    "\n",
    "# Run the chatbot\n",
    "if __name__ == \"__main__\":\n",
    "    chat_with_pdf_bot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
